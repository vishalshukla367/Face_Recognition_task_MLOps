{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shukl\\.conda\\envs\\mask_R_CNN\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# VGG16 was designed to work on 224 x 224 pixel input images sizes\n",
    "img_rows = 224\n",
    "img_cols = 224 \n",
    "\n",
    "#include_top=False removes the output layer of the model\n",
    "base_model = VGG16(weights = 'imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (img_rows, img_cols, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get only the name\n",
    "base_model.layers[0].__class__.__name__\n",
    "#To see the input/output of a particular layer\n",
    "base_model.layers[0].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freezing all the layers by making their trainable=False\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D False\n",
      "2 Conv2D False\n",
      "3 MaxPooling2D False\n",
      "4 Conv2D False\n",
      "5 Conv2D False\n",
      "6 MaxPooling2D False\n",
      "7 Conv2D False\n",
      "8 Conv2D False\n",
      "9 Conv2D False\n",
      "10 MaxPooling2D False\n",
      "11 Conv2D False\n",
      "12 Conv2D False\n",
      "13 Conv2D False\n",
      "14 MaxPooling2D False\n",
      "15 Conv2D False\n",
      "16 Conv2D False\n",
      "17 Conv2D False\n",
      "18 MaxPooling2D False\n"
     ]
    }
   ],
   "source": [
    "#Checking this\n",
    "base_model.layers[12].trainable\n",
    "\n",
    "# Let's print our layers \n",
    "for (i,layer) in enumerate(base_model.layers):\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'block5_pool/MaxPool:0' shape=(?, 7, 7, 512) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we add our dense layers for a new prediction on top of the base model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "top_model = base_model.output\n",
    "top_model = Flatten()(top_model)\n",
    "top_model = Dense(512, activation='relu')(top_model)   #First added FCL dense layer\n",
    "top_model = Dense(512, activation='relu')(top_model)    #Second added FCL dense layer\n",
    "top_model = Dense(256, activation='relu')(top_model)    #Third added FCL dense layer\n",
    "top_model = Dense(5, activation='softmax')(top_model)    #Output layer with 5 class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_4/Softmax:0' shape=(?, 5) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's see the top_model output\n",
    "top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(?, 224, 224, 3) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMP: Mounting the base_model with the top_model\n",
    "from keras.models import Model\n",
    "newmodel = Model(inputs=base_model.input, outputs=top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_4/Softmax:0' shape=(?, 5) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1e6a0d33da0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e6a0d49668>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e6a0d494a8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1e6a0d68748>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e6a0d68828>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e6a0dab9e8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1e6a0dbdda0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e6a0dbddd8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e6a0df14a8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e6a0e106a0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1e6a0e3c978>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e6a0e3cfd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e6a0e71438>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e6a0e88a58>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1e6a0ec0be0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e6a0ec0e80>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e6a0ed5b70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1e6a0f07710>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1e6a0f27ef0>,\n",
       " <keras.layers.core.Flatten at 0x1e6a47ea160>,\n",
       " <keras.layers.core.Dense at 0x1e6a47ea198>,\n",
       " <keras.layers.core.Dense at 0x1e6a47ea240>,\n",
       " <keras.layers.core.Dense at 0x1e6a47ea390>,\n",
       " <keras.layers.core.Dense at 0x1e6a0f8db38>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 27,955,525\n",
      "Trainable params: 13,240,837\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "newmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 327 images belonging to 5 classes.\n",
      "Found 69 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#Converting to 4D\\nfor img_test in test_generator:\\n    img_test=np.expand_dims(img_test, axis=0)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing our images for recognition\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data=\"D:/home/train/\"\n",
    "test_data=\"D:/home/val/\"\n",
    "\n",
    "#Data image augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    \n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        class_mode='categorical')\n",
    "\n",
    "'''#Converting to 4D\n",
    "for img_train in train_generator:\n",
    "    img_train=np.expand_dims(img_train, axis=0)'''\n",
    " \n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_data,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "'''#Converting to 4D\n",
    "for img_test in test_generator:\n",
    "    img_test=np.expand_dims(img_test, axis=0)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's compile our model\n",
    "from keras.optimizers import RMSprop\n",
    "newmodel.compile(optimizer = RMSprop(lr=0.0001),\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics =['accuracy']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shukl\\.conda\\envs\\mask_R_CNN\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "16/16 [==============================] - 842s 53s/step - loss: 1.3543 - acc: 0.4049 - val_loss: 0.5689 - val_acc: 0.8116\n",
      "Epoch 2/2\n",
      "16/16 [==============================] - 780s 49s/step - loss: 0.7455 - acc: 0.6989 - val_loss: 0.3375 - val_acc: 0.7971\n"
     ]
    }
   ],
   "source": [
    "history = newmodel.fit_generator(train_generator, epochs=2,steps_per_epoch=327 // 20, validation_data=test_generator,\n",
    "                                validation_steps = 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel.save('home_Recognizer_VGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "classifier = load_model('home_Recognizer_VGG16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class - gopi\n",
      "Class - nandan\n",
      "Class - vishal\n",
      "Class - pam\n",
      "Class - vishal\n",
      "Class - gopi\n",
      "Class - pam\n",
      "Class - gopi\n",
      "Class - nandan\n",
      "Class - vedik\n",
      "Class - gopi\n",
      "Class - pam\n",
      "Class - vishal\n",
      "Class - nandan\n",
      "Class - vedik\n",
      "Class - gopi\n",
      "Class - gopi\n",
      "Class - nandan\n",
      "Class - vedik\n",
      "Class - pam\n",
      "Class - nandan\n",
      "Class - vishal\n",
      "Class - gopi\n",
      "Class - vishal\n",
      "Class - pam\n"
     ]
    }
   ],
   "source": [
    "#Testing the model\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "five_home_dict = {\"[0]\": \"kratik\", \n",
    "                      \"[1]\": \"richa\",\n",
    "                      \"[2]\": \"prity\",\n",
    "                      \"[3]\": \"vaidik\",\n",
    "                      \"[4]\": \"vishal\",\n",
    "                     }\n",
    "\n",
    "five_home_dict_n = {\"kratik\": \"kratik\", \n",
    "                      \"richa\": \"richa\",\n",
    "                      \"prity\": \"prity\",\n",
    "                      \"vaidik\": \"vaidik\",\n",
    "                      \"vishal\": \"vishal\",\n",
    "                      }\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "    celeb =five_home_dict[str(pred)]\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, celeb, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "def getRandomImage(path):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    print(\"Class - \" + five_home_dict_n[str(path_class)])\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "for i in range(0,25):\n",
    "    input_im = getRandomImage(\"D:/home/val/\")\n",
    "    input_original = input_im.copy()\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "    input_im = input_im / 255.\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "    \n",
    "    # Get Prediction\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "    \n",
    "    # Show image with predicted class\n",
    "    draw_test(\"Prediction\", res, input_original) \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
